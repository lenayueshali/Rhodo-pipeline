# -*- coding: utf-8 -*-
"""Density weighing and increment detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NuS6oRctSleftrzUflUq2ZmVhcDfzUqP
"""

# -*- coding: utf-8 -*-
"""
Density-derived growth rate and increment comparison

Implements:
  1) Density-weighted growth rate along poststain microCT curves
  2) Semi-automated increment detection from Curve 6 density
  3) DTW alignment and regression vs manual Curve 6 increments
"""

# --------------------------------------------------------------------
# SETUP: imports and Drive
# --------------------------------------------------------------------
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from datetime import datetime, timedelta

from scipy.signal import savgol_filter, find_peaks
import statsmodels.api as sm

!pip install dtaidistance
from dtaidistance import dtw

from google.colab import drive
drive.mount('/content/drive')

# --------------------------------------------------------------------
# 1. LOAD AND PREPROCESS DENSITY CURVES (1–4)
# --------------------------------------------------------------------

base = "./drive/MyDrive/PhD data/microCT/measurement data/"

df_poststain1 = pd.read_csv(base + "post stain growth_1000.csv",
                            header=None, names=["x", "y"])
remove_first1 = 81
df_poststain1 = df_poststain1.iloc[remove_first1:].reset_index(drop=True)
df_poststain1["x"] = df_poststain1["x"] - df_poststain1["x"].iloc[0]

df_poststain2 = pd.read_csv(base + "post stain growth_1000_2.csv",
                            header=None, names=["x", "y"])
remove_first2 = 112
df_poststain2 = df_poststain2.iloc[remove_first2:].reset_index(drop=True)
df_poststain2["x"] = df_poststain2["x"] - df_poststain2["x"].iloc[0]

df_poststain3 = pd.read_csv(base + "post stain growth_1000_3.csv",
                            header=None, names=["x", "y"])
remove_last3 = 32
df_poststain3 = df_poststain3.iloc[:-remove_last3].reset_index(drop=True)
df_poststain3["x"] = -df_poststain3["x"] + df_poststain3["x"].values[-1]
df_poststain3 = df_poststain3.iloc[::-1].reset_index(drop=True)

df_poststain4 = pd.read_csv(base + "post stain growth_1000_4.csv",
                            header=None, names=["x", "y"])
remove_last4 = 19
df_poststain4 = df_poststain4.iloc[:-remove_last4].reset_index(drop=True)
df_poststain4["x"] = -df_poststain4["x"] + df_poststain4["x"].values[-1]
df_poststain4 = df_poststain4.iloc[::-1].reset_index(drop=True)

density_curves = [df_poststain1, df_poststain2, df_poststain3, df_poststain4]

# --------------------------------------------------------------------
# 2. DENSITY-WEIGHTED GROWTH RATE (v(x) ∝ 1/p(x))
# --------------------------------------------------------------------

start_date = datetime(2024, 3, 13, 12)   # alizarin stain
end_date   = datetime(2024, 7, 23, 12)   # microCT scan
total_days = (end_date - start_date).days

def compute_density_weighted_time(df_poststain, start_date, end_date):
    """
    Map distance x along a curve to time using v(x) = k / p(x).

    Returns DataFrame with:
      x, density, dt (days), DateTime, v (µm/day)
    """
    x = df_poststain["x"].values
    p = df_poststain["y"].values

    dx = np.diff(x)
    p_i = p[:-1]

    dt_raw = p_i * dx  # ∝ p_i Δx_i
    total_days = (end_date - start_date).days
    dt = dt_raw / dt_raw.sum() * total_days  # Δt_i = P_i T

    cumulative_days = np.insert(np.cumsum(dt), 0, 0)
    dates = [start_date + timedelta(days=float(d)) for d in cumulative_days]

    v = dx / dt  # v(x_i) = Δx_i / Δt_i

    return pd.DataFrame({
        "x": x[:-1],
        "density": p_i,
        "dt": dt,
        "DateTime": dates[:-1],
        "v": v,
    })

def average_curves(dfs, n_points=1000):
    """
    Average multiple density curves onto a common x-grid.

    Returns DataFrame with columns x, y (mean), y_std.
    """
    x_common = np.linspace(
        min(df["x"].min() for df in dfs),
        max(df["x"].max() for df in dfs),
        n_points,
    )
    ys_interp = [np.interp(x_common, df["x"], df["y"]) for df in dfs]
    y_mean = np.mean(ys_interp, axis=0)
    y_std  = np.std(ys_interp, axis=0)
    return pd.DataFrame({"x": x_common, "y": y_mean, "y_std": y_std})

# Average density profile and density-weighted time axis
average_density = average_curves(density_curves, n_points=1000)
average_growth_rates = compute_density_weighted_time(
    average_density[["x", "y"]].rename(columns={"y": "y"}),
    start_date,
    end_date,
)

# Save for downstream use
average_growth_rates.to_csv(
    "./drive/MyDrive/PhD data/Rhodolith papers/average_growth_rates.csv",
    index=False,
)

# Optional plot similar to the grayscale growth-rate plots
plt.figure(figsize=(10, 4))
plt.plot(average_growth_rates["DateTime"],
         average_growth_rates["v"], "-", color="k")
plt.xlabel("Date")
plt.ylabel("Growth rate [µm/day]")
plt.title("Density-weighted growth rate (average curve)")
plt.grid(True)
plt.tight_layout()
plt.show()

# --------------------------------------------------------------------
# 3. CURVE 6: AUTOMATED INCREMENT DETECTION VS MANUAL
# --------------------------------------------------------------------

# Load manual microCT increment file
inc_path = "./drive/MyDrive/PhD data/microCT/measurement data/afe5-1 microct data.xlsx"
df_incwidth = pd.read_excel(inc_path)
df_incwidth.drop(
    columns=[c for c in df_incwidth.columns if str(c).startswith("Unnamed")],
    inplace=True,
    errors="ignore",
)
df_incwidth.columns = [c.replace(" ", "") for c in df_incwidth.columns]

# Select Curve 6 section (same as your tuned parameters)
remove_6_start = 41
remove_6_end   = 35
curve6x = df_incwidth["curve6x"].values
curve6y = df_incwidth["curve6y"].values

x_section_raw = (curve6x[-1] - curve6x)[-remove_6_start:remove_6_end:-1]
x_section = x_section_raw - x_section_raw[0]
y_section = curve6y[-remove_6_start:remove_6_end:-1]

# Savitzky–Golay smoothing
window_length = 11
polyorder     = 2
if len(y_section) >= window_length:
    y_smooth = savgol_filter(y_section, window_length, polyorder)
else:
    print(
        f"Warning: Curve 6 section length ({len(y_section)}) "
        f"< window_length ({window_length}); using raw density."
    )
    y_smooth = y_section

# Tuned peak-finding parameters (as in your final block)
peak_distance   = 10
peak_prominence = 0.005

peaks, _   = find_peaks(y_smooth,  distance=peak_distance,
                        prominence=peak_prominence)
valleys, _ = find_peaks(-y_smooth, distance=peak_distance,
                        prominence=peak_prominence)

ext_idx = np.sort(np.concatenate([peaks, valleys]))
ext_idx = ext_idx[(ext_idx > 0) & (ext_idx < len(x_section) - 1)]

if len(ext_idx) < 2:
    print("Warning: < 2 extrema found; derived increments empty.")
    derived_increments = np.array([])
    derived_positions  = np.array([])
else:
    derived_positions  = x_section[ext_idx[:-1]]
    derived_increments = np.diff(x_section[ext_idx])

# Manual increments for Curve 6
increments_6 = df_incwidth["curve6"].values
manual_mask = ~np.isnan(increments_6)
manual_increments = increments_6[manual_mask]
manual_positions  = np.concatenate(([0], manual_increments.cumsum()[:-1]))

print(f"Cleaned manual increments: {len(manual_increments)}")

# --------------------------------------------------------------------
# 4. DTW ALIGNMENT AND REGRESSION (MANUAL VS AUTOMATED)
# --------------------------------------------------------------------

derived_seq = np.asarray(derived_increments)
manual_seq  = np.asarray(manual_increments)
derived_seq = derived_seq[~np.isnan(derived_seq)]
manual_seq  = manual_seq[~np.isnan(manual_seq)]

if len(derived_seq) == 0 or len(manual_seq) == 0:
    print("Derived or manual sequence empty; cannot perform DTW.")
else:
    print("\nStarting DTW alignment")
    print("  Derived length:", len(derived_seq))
    print("  Manual length :", len(manual_seq))

    try:
        path = dtw.warping_path(derived_seq, manual_seq)
        derived_aligned = derived_seq[[p[0] for p in path]]
        manual_aligned  = manual_seq[[p[1] for p in path]]
        print("  DTW path length:", len(path))
    except Exception as e:
        print(f"DTW error: {e}")
        derived_aligned = np.array([])
        manual_aligned  = np.array([])

    if len(derived_aligned) > 0:
        # OLS: manual ~ derived
        y = manual_aligned
        X = derived_aligned
        mask = ~np.isnan(X) & ~np.isnan(y)
        y_clean = y[mask]
        X_clean = X[mask]

        if len(y_clean) > 0:
            X_mat = sm.add_constant(X_clean.reshape(-1, 1))
            model = sm.OLS(y_clean, X_mat).fit()
            print("\nRegression: Manual vs Derived (DTW-aligned)")
            print(model.summary())

            # Plot aligned sequences
            plt.figure(figsize=(10, 4))
            plt.plot(derived_aligned, ".-", label="Derived aligned")
            plt.plot(manual_aligned, ".-", label="Manual aligned")
            plt.xlabel("Aligned increment index")
            plt.ylabel("Increment width [µm]")
            plt.title("Curve 6: DTW-aligned increment series")
            plt.legend()
            plt.grid(True)
            plt.tight_layout()
            plt.show()

            # Regression scatter
            plt.figure(figsize=(6, 5))
            plt.scatter(X_clean, y_clean, alpha=0.5, label="Aligned points")
            plt.plot(X_clean, model.predict(X_mat), color="red",
                     label="OLS fit")
            plt.xlabel("Derived increment width [µm]")
            plt.ylabel("Manual increment width [µm]")
            plt.title("Curve 6: manual vs automated increment widths")
            plt.legend()
            plt.grid(True)
            plt.tight_layout()
            plt.show()
        else:
            print("No non-NaN points after DTW for regression.")

